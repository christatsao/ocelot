{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "#Our project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "#Local packages loaded from src specifying useful constants, and our custom loader\n",
    "from util.constants import DATA_PATHS\n",
    "from util.dataset import OcelotDatasetLoader, PixelThreshold\n",
    "from util.unet import Unet\n",
    "from util.evaluate import evaluate\n",
    "\n",
    "#other modules of interest\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "from torchvision import transforms as transf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.losses import DiceCELoss, DiceLoss, MaskedDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "my_device = torch.device(device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin_memory = True if my_device == 'cuda' else False\n",
    "d_type_f32 = torch.float32\n",
    "batch_size = 1\n",
    "learning_rate= 1e-3\n",
    "weight_decay = 1e-3\n",
    "nepochs = 10\n",
    "val_percent=0.1\n",
    "train_percent = 1 - val_percent\n",
    "image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()])\n",
    "mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)])\n",
    "\n",
    "#First we need to specify some info on our model: we have 3 channels RGB, 1 class: tissue\n",
    "model = Unet(n_channels=3, n_classes=1)\n",
    "\n",
    "print(my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS,\n",
    "                                    dataToLoad = 'Tissue',\n",
    "                                    image_transforms=image_transforms,\n",
    "                                    mask_transforms=mask_transforms)\n",
    "\n",
    "#Establish a train/validation split size\n",
    "TrainValSplit = [int(0.8*len(TissTrainData)), len(TissTrainData) - int(0.8*len(TissTrainData))]\n",
    "\n",
    "#Establish our training and validation data using torch's built in random_split on our own formatted data\n",
    "TrainingData, ValidationData = torch.utils.data.random_split(TissTrainData, [train_percent, val_percent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(TissTrainData, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "TissValLoader = DataLoader(ValidationData, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ocelot dataset...\n",
      "Found 400 data samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/320 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 320/320 [00:32<00:00,  9.98it/s]\n",
      "Epoch 2/2: 100%|██████████| 320/320 [00:32<00:00,  9.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def tiss_training_loop(\n",
    "    model,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size:         int = 128,\n",
    "    learning_rate:      float = 0.0001,\n",
    "    val_percent:        float = 0.2,\n",
    "    amp:                bool = False,\n",
    "    weight_decay:       float = 1e-3,\n",
    "    momentum:           float = 0.98,\n",
    "    gradient_clipping:  float = 1.0,\n",
    "    image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()]),\n",
    "    mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)]),\n",
    "):\n",
    "    #Loading our data, performing necessary splits (update with test set in future), and send to loader\n",
    "    print(\"Loading Ocelot dataset...\")\n",
    "\n",
    "    training_data = OcelotDatasetLoader(paths=DATA_PATHS,\n",
    "                                        dataToLoad='Tissue',\n",
    "                                        image_transforms=image_transforms,\n",
    "                                        mask_transforms=mask_transforms)\n",
    "    train_percent = 1 - val_percent\n",
    "    train_N, val_N = [int(train_percent*len(training_data)), \n",
    "                      int(val_percent*len(training_data))]\n",
    "    train_split, val_split = torch.utils.data.random_split(training_data, \n",
    "                                                           [train_percent, val_percent])\n",
    "    train_loader = DataLoader(train_split, \n",
    "                              batch_size=batch_size, \n",
    "                              num_workers=4)\n",
    "    val_loader = DataLoader(val_split, \n",
    "                            batch_size=batch_size, \n",
    "                            num_workers=4)\n",
    "\n",
    "    print(f\"Found {len(training_data)} data samples.\")   \n",
    "        \n",
    "    #Initialize optimizer, loss, learning rate, and loss scaling\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    #criterion = torch.nn.BCEWithLogitsLoss() if model.n_classes == 1 else None #TODO: IMPLEMENT BEHAVIOR FOR NON BINARY SEGMENTATION (ensure model.n_classes=1 for now)\n",
    "    criterion = DiceCELoss(sigmoid=True)\n",
    "\n",
    "    #we use max here as our purpose is to maximize our measured metric (DICE score of 1 is better: more mask similarity)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "    \n",
    "    #Only for AMP. prevents loss of values due to switch between multiple formats\n",
    "    grad_scaler = torch.cuda.amp.grad_scaler.GradScaler(enabled=amp)\n",
    "    #global_step = 0\n",
    "    #epoch_loss = 0\n",
    "    model.to(device)\n",
    "    val_loss_metric = []\n",
    "    train_loss_metric = []\n",
    "\n",
    "    #Begin training\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        with tqdm(total=train_N, desc=f'Epoch {epoch+1}/{epochs}') as progress_bar:\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch[0], batch[1]\n",
    "                assert images.shape[1] == model.n_channels, f\"Expected {model.n_channels} channels from image but received {images.shape[1]} channels instead.\"\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last if amp==True else torch.preserve_format)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                with torch.autocast(device.type if device.type == 'cuda' else 'cpu', enabled=amp):\n",
    "                    infer_masks = model(images)\n",
    "                    \n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(infer_masks, true_masks.float())\n",
    "                        epoch_loss += loss.detach().cpu()\n",
    "                        #loss += 0.5 * dice_score #TODO: loss += dice score?\n",
    "                    \n",
    "                    else:\n",
    "                        #TODO: EVALUATE CRITERION FOR MULTICLASS SEGMENTATION\n",
    "                        loss = ...\n",
    "                        return NotImplementedError\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #Scales w/ AMP enabled from loss and does backprop\n",
    "                grad_scaler.scale(loss).backward()\n",
    "\n",
    "                #Grad clipping restricts gradient to a range. Research vanishing gradient for more.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                \n",
    "                #Step the optimizer for new model parameters (keeping grad scaling in mind assuming AMP)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                progress_bar.update(images.shape[0])\n",
    "\n",
    "                #global_step += 1\n",
    "                #Add to our epoch loss from our element in loss tensor\n",
    "                #epoch_loss += loss.item() #TODO: TRAIN LOSS\n",
    "            \n",
    "            #Calculate train loss\n",
    "            train_loss_metric.append(epoch_loss/(train_N/batch_size))\n",
    "\n",
    "            #Move on to evaluation\n",
    "            val_metric = evaluate(model, val_loader, device, amp=False) #TODO: UPDATE EVALUATION METHOD FOR MULTICLASS\n",
    "            scheduler.step()\n",
    "\n",
    "            val_loss_metric.append(val_metric)\n",
    "\n",
    "            #TODO: Deepcopy and save the model with WORST/best? val accuracy\n",
    "\n",
    "    return train_loss_metric, val_loss_metric\n",
    "\n",
    "train_score, val_score = tiss_training_loop(model=model,\n",
    "                           device=my_device,\n",
    "                           epochs=2,\n",
    "                           batch_size=32,\n",
    "                           amp=False,\n",
    "                           val_percent=0.2,\n",
    "                           mask_transforms=mask_transforms,\n",
    "                           image_transforms=image_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#plt.plot(train_score)\n",
    "#plt.plot(val_score)\n",
    "print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m y_true \u001b[39m=\u001b[39m TissTrainLoader\u001b[39m.\u001b[39mdataset[\u001b[39m8\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m y_image \u001b[39m=\u001b[39m TissTrainLoader\u001b[39m.\u001b[39mdataset[\u001b[39m8\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m y_pred \u001b[39m=\u001b[39m model(y_image\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(y_true)\n\u001b[0;32m     16\u001b[0m \u001b[39m#print(dice_coef(y_pred, y_pred))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\OneDrive\\Documents\\WorkDirectory\\REU_portfolio\\Ocelot\\util\\unet.py:90\u001b[0m, in \u001b[0;36mUnet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 90\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minc(x)\n\u001b[0;32m     91\u001b[0m     x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown1(x1)\n\u001b[0;32m     92\u001b[0m     x3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown2(x2)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\OneDrive\\Documents\\WorkDirectory\\REU_portfolio\\Ocelot\\util\\unet.py:21\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdouble_conv(x)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conv_forward(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()])\n",
    "mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)])\n",
    "\n",
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS, dataToLoad = 'Tissue', mask_transforms=mask_transforms, image_transforms=image_transforms)\n",
    "\n",
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(TissTrainData, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "y_true = TissTrainLoader.dataset[8][1]\n",
    "y_image = TissTrainLoader.dataset[8][0]\n",
    "model.to(torch.device(device='cpu'))\n",
    "y_pred = model(y_image.unsqueeze(0))\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "#print(dice_coef(y_pred, y_pred))\n",
    "\n",
    "y_out = y_true.squeeze().cpu().numpy()\n",
    "predicted_mask = Image.fromarray((y_out * 255).astype(np.uint8))\n",
    "#predicted_mask\n",
    "\n",
    "#dice_coef(y_pred, y_true)\n",
    "plt.imshow(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6096161109209061"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, TissTrainLoader, device=my_device, amp=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
