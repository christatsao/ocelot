{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "#Our project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "#Local packages loaded from src specifying useful constants, and our custom loader\n",
    "from util.constants import DATA_PATHS\n",
    "from util.dataset import OcelotDatasetLoader, predict_segmentation_img\n",
    "from util.unet import Unet\n",
    "\n",
    "#other modules of interest\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as transf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_device = torch.device(device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin_memory = True if my_device == 'cuda' else False\n",
    "d_type_f32 = torch.float32\n",
    "batch_size = 128\n",
    "learning_rate= 1e-3\n",
    "weight_decay = 1e-3\n",
    "nepochs = 10\n",
    "transforms = transf.Compose([transf.ToTensor()])\n",
    "\n",
    "#First we need to specify some info on our model: we have 3 channels RGB, 1 class: tissue\n",
    "model = Unet(n_channels=3, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS, dataToLoad = 'Tissue', transforms=transforms)\n",
    "\n",
    "#Establish a train/validation split size\n",
    "TrainValSplit = [int(0.8*len(TissTrainData)), len(TissTrainData) - int(0.8*len(TissTrainData))]\n",
    "\n",
    "#Establish our training and validation data using torch's built in random_split on our own formatted data\n",
    "TrainingData, ValidationData = torch.utils.data.random_split(TissTrainData, TrainValSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(TissTrainData, batch_size=batch_size, num_workers=4)\n",
    "TissValLoader = DataLoader(ValidationData, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAAAAAQACAAAAABadnRfAAAEEElEQVR4nO3BMQEAAADCoPVPbQdvoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4DBPAAAfqrrvYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1024x1024>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see take some subset of our original data from data loader and see what our tissue mask looks like before training!\n",
    "indices =  [0,1]\n",
    "subset = torch.utils.data.Subset(TrainingData, indices)\n",
    "MaskTestData = DataLoader(dataset = subset, batch_size=batch_size, num_workers=4)\n",
    "sample_image = MaskTestData.dataset[0][0]\n",
    "predict_segmentation_img(model, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ocelot dataset...\n",
      "Found 400 data samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   9%|â–‰         | 30/320 [00:52<08:26,  1.75s/img] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m train \u001b[39m=\u001b[39m tiss_training_loop(model\u001b[39m=\u001b[39mmodel, device\u001b[39m=\u001b[39mmy_device, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, amp\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, val_percent\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m, in \u001b[0;36mtiss_training_loop\u001b[1;34m(model, device, epochs, batch_size, learning_rate, val_percent, save_checkpoint, amp, weight_decay, momentum, gradient_clipping)\u001b[0m\n\u001b[0;32m     54\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m grad_scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 56\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), gradient_clipping)\n\u001b[0;32m     57\u001b[0m grad_scaler\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[0;32m     58\u001b[0m grad_scaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m ((device, _), [grads]) \u001b[39min\u001b[39;00m grouped_grads\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m (foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m foreach) \u001b[39mand\u001b[39;00m _has_foreach_support(grads, device\u001b[39m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         torch\u001b[39m.\u001b[39m_foreach_mul_(grads, clip_coef_clamped\u001b[39m.\u001b[39mto(device))  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[39melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforeach=True was passed, but can\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt use the foreach API on \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m.\u001b[39mtype\u001b[39m}\u001b[39;00m\u001b[39m tensors\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tiss_training_loop(\n",
    "    model,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size:         int = 128,\n",
    "    learning_rate:      float = 1e-3,\n",
    "    val_percent:        float = 0.2,\n",
    "    save_checkpoint:    bool = True,\n",
    "    amp:                bool = False,\n",
    "    weight_decay:       float = 1e-3,\n",
    "    momentum:           float = 0.9,\n",
    "    gradient_clipping:  float = 1.0\n",
    "):\n",
    "    transforms = transf.Compose([transf.ToTensor()])\n",
    "\n",
    "    #Loading our data, performing necessary splits (update with test set in future), and send to loader\n",
    "    print(\"Loading Ocelot dataset...\")\n",
    "    training_data = OcelotDatasetLoader(paths = DATA_PATHS, dataToLoad = 'Tissue', transforms=transforms)\n",
    "    train_percent = 1 - val_percent\n",
    "    train_N, val_N = [int(train_percent*len(training_data)), int(val_percent*len(training_data))]\n",
    "    train_split, val_split = torch.utils.data.random_split(training_data, [train_percent, val_percent])\n",
    "    train_loader = DataLoader(train_split, batch_size=batch_size, num_workers=4)\n",
    "    val_loader = DataLoader(val_split, batch_size=batch_size, num_workers=4)  \n",
    "    print(f\"Found {len(training_data)} data samples.\")   \n",
    "    \n",
    "    #TODO: Initialize logging???\n",
    "    \n",
    "    #Initialize optimizer, loss, learning rate, and loss scaling\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss() #binary cross entropy w/ logit loss (BCE + softmax)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5) #we use max here as our purpose is to maximize our measured metric (DICE score of 1 is better: more mask similarity)\n",
    "    grad_scaler = torch.cuda.amp.grad_scaler.GradScaler(enabled=amp) #only for AMP. prevents loss of values due to switch between multiple fp formats\n",
    "    global_step = 0\n",
    "\n",
    "    #Begin training\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        \n",
    "        with tqdm(total=train_N, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch[0], batch[1]\n",
    "                assert images.shape[1] == model.n_channels, f\"Expected {model.n_channels} channels from image but received {images.shape[1]} channels instead.\"\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last if amp==True else torch.preserve_format)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                with torch.autocast(device.type if device.type == 'cuda' else 'cpu', enabled=amp):\n",
    "                    infer_masks = model(images)\n",
    "                    loss = criterion(infer_masks, true_masks) #TODO: to squeeze or not to squeeze, that is the question.\n",
    "                    #TODO: CALC DICE LOSS KERAS?\n",
    "                    #TODO: loss += dice score\n",
    "\n",
    "                optimizer.zero_grad() #OPTIONAL: set_to_none=True\n",
    "                grad_scaler.scale(loss).backward() #scales w/ AMP enabled from loss and backprop\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "\n",
    "                pass\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "train = tiss_training_loop(model=model, device=my_device, epochs=10, batch_size=1, amp=False, val_percent=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_reserved(0))\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
