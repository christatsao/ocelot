{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "#Our project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "#Local packages loaded from src specifying useful constants, and our custom loader\n",
    "from util.constants import DATA_PATHS\n",
    "from util.dataset import OcelotDatasetLoader, PixelThreshold\n",
    "from util.unet import Unet\n",
    "from util.evaluate import evaluate\n",
    "\n",
    "#other modules of interest\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "from torchvision import transforms as transf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.losses import DiceCELoss, DiceLoss, MaskedDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "my_device = torch.device(device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin_memory = True if my_device == 'cuda' else False\n",
    "d_type_f32 = torch.float32\n",
    "batch_size = 1\n",
    "learning_rate= 1e-3\n",
    "weight_decay = 1e-3\n",
    "nepochs = 10\n",
    "val_percent=0.1\n",
    "train_percent = 1 - val_percent\n",
    "image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()])\n",
    "mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)])\n",
    "\n",
    "#First we need to specify some info on our model: we have 3 channels RGB, 1 class: tissue\n",
    "model = Unet(n_channels=3, n_classes=1)\n",
    "\n",
    "print(my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS,\n",
    "                                    dataToLoad = 'Tissue',\n",
    "                                    image_transforms=image_transforms,\n",
    "                                    mask_transforms=mask_transforms)\n",
    "\n",
    "#Establish a train/validation split size\n",
    "TrainValSplit = [int(0.8*len(TissTrainData)), len(TissTrainData) - int(0.8*len(TissTrainData))]\n",
    "\n",
    "#Establish our training and validation data using torch's built in random_split on our own formatted data\n",
    "TrainingData, ValidationData = torch.utils.data.random_split(TissTrainData, [train_percent, val_percent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(TissTrainData, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "TissValLoader = DataLoader(ValidationData, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ocelot dataset...\n",
      "Found 400 data samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 320/320 [00:30<00:00, 67.93it/s]c:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Epoch 1/50: 100%|██████████| 320/320 [00:34<00:00,  9.40it/s]\n",
      "Epoch 2/50: 100%|██████████| 320/320 [00:27<00:00, 11.44it/s]\n",
      "Epoch 3/50: 100%|██████████| 320/320 [00:28<00:00, 11.26it/s]\n",
      "Epoch 4/50: 100%|██████████| 320/320 [00:28<00:00, 11.04it/s]\n",
      "Epoch 5/50: 100%|██████████| 320/320 [00:28<00:00, 11.13it/s]\n",
      "Epoch 6/50: 100%|██████████| 320/320 [00:28<00:00, 11.04it/s]\n",
      "Epoch 7/50: 100%|██████████| 320/320 [00:28<00:00, 11.20it/s]\n",
      "Epoch 8/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 9/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 10/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 11/50: 100%|██████████| 320/320 [00:28<00:00, 11.19it/s]\n",
      "Epoch 12/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 13/50: 100%|██████████| 320/320 [00:29<00:00, 10.81it/s]\n",
      "Epoch 14/50: 100%|██████████| 320/320 [00:28<00:00, 11.20it/s]\n",
      "Epoch 15/50: 100%|██████████| 320/320 [00:28<00:00, 11.20it/s]\n",
      "Epoch 16/50: 100%|██████████| 320/320 [00:29<00:00, 10.87it/s]\n",
      "Epoch 17/50: 100%|██████████| 320/320 [00:29<00:00, 10.84it/s]\n",
      "Epoch 18/50: 100%|██████████| 320/320 [00:28<00:00, 11.11it/s]\n",
      "Epoch 19/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 20/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 21/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 22/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 23/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 24/50: 100%|██████████| 320/320 [00:28<00:00, 11.11it/s]\n",
      "Epoch 25/50: 100%|██████████| 320/320 [00:28<00:00, 11.25it/s]\n",
      "Epoch 26/50: 100%|██████████| 320/320 [00:28<00:00, 11.22it/s]\n",
      "Epoch 27/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 28/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 29/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 30/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 31/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 32/50: 100%|██████████| 320/320 [00:28<00:00, 11.26it/s]\n",
      "Epoch 33/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 34/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 35/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 36/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 37/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 38/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 39/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 40/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 41/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 42/50: 100%|██████████| 320/320 [00:28<00:00, 11.36it/s]\n",
      "Epoch 43/50: 100%|██████████| 320/320 [00:28<00:00, 11.34it/s]\n",
      "Epoch 44/50: 100%|██████████| 320/320 [00:28<00:00, 11.36it/s]\n",
      "Epoch 45/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 46/50: 100%|██████████| 320/320 [00:28<00:00, 11.27it/s]\n",
      "Epoch 47/50: 100%|██████████| 320/320 [00:28<00:00, 11.35it/s]\n",
      "Epoch 48/50: 100%|██████████| 320/320 [00:28<00:00, 11.28it/s]\n",
      "Epoch 49/50: 100%|██████████| 320/320 [00:28<00:00, 11.16it/s]\n",
      "Epoch 50/50: 100%|██████████| 320/320 [00:28<00:00, 11.23it/s]\n"
     ]
    }
   ],
   "source": [
    "def tiss_training_loop(\n",
    "    model,\n",
    "    device,\n",
    "    epochs,\n",
    "    batch_size:         int = 128,\n",
    "    learning_rate:      float = 0.0001,\n",
    "    val_percent:        float = 0.2,\n",
    "    amp:                bool = False,\n",
    "    weight_decay:       float = 1e-3,\n",
    "    momentum:           float = 0.98,\n",
    "    gradient_clipping:  float = 1.0,\n",
    "    image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()]),\n",
    "    mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)]),\n",
    "):\n",
    "    #Loading our data, performing necessary splits (update with test set in future), and send to loader\n",
    "    print(\"Loading Ocelot dataset...\")\n",
    "\n",
    "    training_data = OcelotDatasetLoader(paths=DATA_PATHS,\n",
    "                                        dataToLoad='Tissue',\n",
    "                                        image_transforms=image_transforms,\n",
    "                                        mask_transforms=mask_transforms)\n",
    "    train_percent = 1 - val_percent\n",
    "    train_N, val_N = [int(train_percent*len(training_data)), \n",
    "                      int(val_percent*len(training_data))]\n",
    "    train_split, val_split = torch.utils.data.random_split(training_data, \n",
    "                                                           [train_percent, val_percent])\n",
    "    train_loader = DataLoader(train_split, \n",
    "                              batch_size=batch_size, \n",
    "                              num_workers=4)\n",
    "    val_loader = DataLoader(val_split, \n",
    "                            batch_size=batch_size, \n",
    "                            num_workers=4)\n",
    "\n",
    "    print(f\"Found {len(training_data)} data samples.\")   \n",
    "        \n",
    "    #Initialize optimizer, loss, learning rate, and loss scaling\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    #criterion = torch.nn.BCEWithLogitsLoss() if model.n_classes == 1 else None #TODO: IMPLEMENT BEHAVIOR FOR NON BINARY SEGMENTATION (ensure model.n_classes=1 for now)\n",
    "    criterion = DiceCELoss(sigmoid=True)\n",
    "\n",
    "    #we use max here as our purpose is to maximize our measured metric (DICE score of 1 is better: more mask similarity)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "    \n",
    "    #Only for AMP. prevents loss of values due to switch between multiple formats\n",
    "    grad_scaler = torch.cuda.amp.grad_scaler.GradScaler(enabled=amp)\n",
    "    #global_step = 0\n",
    "    #epoch_loss = 0\n",
    "    model.to(device)\n",
    "    val_loss_metric = []\n",
    "    train_loss_metric = []\n",
    "\n",
    "    #Begin training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        with tqdm(total=train_N, desc=f'Epoch {epoch+1}/{epochs}') as progress_bar:\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch[0], batch[1]\n",
    "                assert images.shape[1] == model.n_channels, f\"Expected {model.n_channels} channels from image but received {images.shape[1]} channels instead.\"\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last if amp==True else torch.preserve_format)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                with torch.autocast(device.type if device.type == 'cuda' else 'cpu', enabled=amp):\n",
    "                    infer_masks = model(images)\n",
    "                    \n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(infer_masks, true_masks.float())\n",
    "                        train_loss = loss\n",
    "                        train_loss_metric.append(train_loss.detach().cpu())\n",
    "                        #loss += 0.5 * dice_score #TODO: loss += dice score?\n",
    "                    \n",
    "                    else:\n",
    "                        #TODO: EVALUATE CRITERION FOR MULTICLASS SEGMENTATION\n",
    "                        loss = ...\n",
    "                        return NotImplementedError\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #Scales w/ AMP enabled from loss and does backprop\n",
    "                grad_scaler.scale(loss).backward()\n",
    "\n",
    "                #Grad clipping restricts gradient to a range. Research vanishing gradient for more.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                \n",
    "                #Step the optimizer for new model parameters (keeping grad scaling in mind assuming AMP)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                progress_bar.update(images.shape[0])\n",
    "\n",
    "                #global_step += 1\n",
    "                #Add to our epoch loss from our element in loss tensor\n",
    "                #epoch_loss += loss.item() #TODO: TRAIN LOSS\n",
    "\n",
    "            #Move on to evaluation\n",
    "            val_metric = evaluate(model, val_loader, device, amp=False) #TODO: UPDATE EVALUATION METHOD FOR MULTICLASS\n",
    "            scheduler.step(val_metric)\n",
    "\n",
    "            val_loss_metric.append(val_metric)\n",
    "\n",
    "            #TODO: Deepcopy and save the model with WORST/best? val accuracy\n",
    "\n",
    "    return train_loss_metric, val_loss_metric\n",
    "\n",
    "train_score, val_score = tiss_training_loop(model=model,\n",
    "                           device=my_device,\n",
    "                           epochs=50,\n",
    "                           batch_size=32,\n",
    "                           amp=False,\n",
    "                           val_percent=0.2,\n",
    "                           mask_transforms=mask_transforms,\n",
    "                           image_transforms=image_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c674227110>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(train_score)\n",
    "plt.plot(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m y_true \u001b[39m=\u001b[39m TissTrainLoader\u001b[39m.\u001b[39mdataset[\u001b[39m8\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m y_image \u001b[39m=\u001b[39m TissTrainLoader\u001b[39m.\u001b[39mdataset[\u001b[39m8\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m y_pred \u001b[39m=\u001b[39m model(y_image\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(y_true)\n\u001b[0;32m     16\u001b[0m \u001b[39m#print(dice_coef(y_pred, y_pred))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\OneDrive\\Documents\\WorkDirectory\\REU_portfolio\\Ocelot\\util\\unet.py:90\u001b[0m, in \u001b[0;36mUnet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 90\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minc(x)\n\u001b[0;32m     91\u001b[0m     x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown1(x1)\n\u001b[0;32m     92\u001b[0m     x3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown2(x2)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\OneDrive\\Documents\\WorkDirectory\\REU_portfolio\\Ocelot\\util\\unet.py:21\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdouble_conv(x)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conv_forward(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "image_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor()])\n",
    "mask_transforms = transf.Compose([transf.Resize((128,128)), transf.ToTensor(), PixelThreshold(lower_thresh=1, upper_thresh=255)])\n",
    "\n",
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS, dataToLoad = 'Tissue', mask_transforms=mask_transforms, image_transforms=image_transforms)\n",
    "\n",
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(TissTrainData, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "y_true = TissTrainLoader.dataset[8][1]\n",
    "y_image = TissTrainLoader.dataset[8][0]\n",
    "y_pred = model(y_image.unsqueeze(0))\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "#print(dice_coef(y_pred, y_pred))\n",
    "\n",
    "y_out = y_true.squeeze().cpu().numpy()\n",
    "predicted_mask = Image.fromarray((y_out * 255).astype(np.uint8))\n",
    "#predicted_mask\n",
    "\n",
    "#dice_coef(y_pred, y_true)\n",
    "plt.imshow(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6096161109209061"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, TissTrainLoader, device=my_device, amp=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
