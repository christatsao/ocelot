{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "#Our project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \n",
    "                                            os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "#Local packages loaded from src specifying useful constants, and our custom loader\n",
    "from util.constants import DATA_PATHS, IMG_TRAIN_CELL_DIR, ANN_TRAIN_CELL_DIR, META_PATH\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import join, split\n",
    "from os import listdir\n",
    "\n",
    "from torchvision import transforms as trfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(abspath):\n",
    "    assert os.path.isfile(abspath), f\"File {os.path.split(abspath)[1]} not found.\"\n",
    "    image = Image.open(abspath)\n",
    "    return image\n",
    "\n",
    "def load_csv(abspath):\n",
    "    assert os.path.isfile(abspath), f\"File {split(abspath)[1]} not found.\"\n",
    "    try:\n",
    "        return pd.read_csv(abspath).to_numpy()\n",
    "    except:\n",
    "        return np.empty((0,3))\n",
    "\n",
    "def load_json(abspath, obj_name):\n",
    "    assert os.path.isfile(abspath), f\"File {split(abspath)[1]} not found.\"\n",
    "    with open(abspath) as jsonFile:\n",
    "        jsonObject = json.load(jsonFile)\n",
    "        jsonFile.close()\n",
    "    x_start = jsonObject['sample_pairs'][obj_name]['cell']['x_start']\n",
    "    x_end = jsonObject['sample_pairs'][obj_name]['cell']['x_end']\n",
    "    y_start = jsonObject['sample_pairs'][obj_name]['cell']['y_start']\n",
    "    y_end = jsonObject['sample_pairs'][obj_name]['cell']['y_end']\n",
    "    return np.array([x_start, x_end]), np.array([y_start, y_end])\n",
    "\n",
    "class MyDataLoader(Dataset):\n",
    "    def __init__(self, paths, data_to_load = None, transforms=None):\n",
    "        self.cell_image_path, self.cell_image_file = paths[0], listdir(paths[0])\n",
    "        self.cell_ann_path, self.cell_ann_file = paths[1], listdir(paths[1])\n",
    "        self.tiss_image_path, self.tiss_image_file = paths[2], listdir(paths[2])\n",
    "        self.tiss_mask_path, self.tiss_mask_file = paths[3], listdir(paths[3])\n",
    "        self.metadata_path = paths[4]\n",
    "        self.transforms = transforms\n",
    "        self.data_to_load = data_to_load\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.cell_image_file) == len(self.cell_ann_file), \"Cell-cell data size mismatch. Rebalancing needed.\"\n",
    "        assert len(self.tiss_image_file) == len(self.tiss_mask_file), \"Tisue-tissue data size mismatch. Rebalancing needed.\"\n",
    "        assert len(self.cell_image_file) == len(self.tiss_image_file), \"Cell-tissue data size mismatch. Rebalancing needed.\"\n",
    "        return len(self.cell_image_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cell_images, cell_anns, tiss_images, tiss_masks, x_coords, y_coords = [], [], [], [], [], []\n",
    "\n",
    "        if isinstance(idx, slice):\n",
    "\n",
    "            #get \n",
    "            for a, b, c, d, e in zip(self.cell_image_file[idx], \n",
    "                                     self.cell_ann_file[idx], \n",
    "                                     self.tiss_image_file[idx],\n",
    "                                     self.tiss_mask_file[idx],\n",
    "                                     self.cell_image_file[idx]\n",
    "                                     ):\n",
    "                cell_image = load_image(join(self.cell_image_path, a))\n",
    "                cell_image = self.transforms(cell_image) if self.transforms else cell_image\n",
    "                cell_images.append(cell_image)\n",
    "\n",
    "            #for x in self.cell_ann_file[idx]:\n",
    "                cell_ann = load_csv(join(self.cell_ann_path, b))\n",
    "                cell_anns.append(cell_ann)\n",
    "\n",
    "            #for x in self.tiss_image_file[idx]:\n",
    "                tiss_image = load_image(join(self.tiss_image_path, c))\n",
    "                tiss_image = self.transforms(tiss_image) if self.transforms else tiss_image\n",
    "                tiss_images.append(tiss_image)\n",
    "\n",
    "            #for x in self.tiss_mask_file[idx]:\n",
    "                tiss_mask = load_image(join(self.tiss_mask_path, d))\n",
    "                tiss_mask = self.transforms(tiss_mask) if self.transforms else tiss_mask\n",
    "                tiss_masks.append(tiss_mask)\n",
    "\n",
    "            #for x in self.cell_image_file[idx]:\n",
    "                x_coord, y_coord = load_json(self.metadata_path, os.path.splitext(e)[0])\n",
    "                x_coords.append(x_coord), y_coords.append(y_coord)\n",
    "        \n",
    "        else:\n",
    "            cell_image = load_image(join(self.cell_image_path, self.cell_image_file[idx]))\n",
    "            cell_image = self.transforms(cell_image) if self.transforms else cell_image\n",
    "            cell_images.append(cell_image)\n",
    "            cell_ann = load_csv(join(self.cell_ann_path, self.cell_ann_file[idx]))\n",
    "            cell_anns.append(cell_ann)\n",
    "            \n",
    "            tiss_image = load_image(join(self.tiss_image_path, self.tiss_image_file[idx]))\n",
    "            tiss_image = self.transforms(tiss_image) if self.transforms else tiss_image\n",
    "            tiss_images.append(tiss_image)\n",
    "            tiss_mask = load_image(join(self.tiss_mask_path, self.tiss_mask_file[idx]))\n",
    "            tiss_mask = self.transforms(tiss_mask) if self.transforms else tiss_mask\n",
    "            tiss_masks.append(tiss_mask)\n",
    "            \n",
    "            x_coord, y_coord = load_json(self.metadata_path, os.path.splitext(self.cell_image_file[idx])[0])\n",
    "            x_coords.append(x_coord), y_coords.append(y_coord)\n",
    "        \n",
    "        if self.transforms:\n",
    "            cell_images = self.transforms(cell_images)\n",
    "        \n",
    "        if self.data_to_load == 'Tissue' or self.data_to_load == 'tissue':\n",
    "            return tiss_images, tiss_masks\n",
    "        \n",
    "        elif self.data_to_load == 'Cell' or self.data_to_load == 'cell':\n",
    "            return cell_images, cell_anns\n",
    "        \n",
    "        else:\n",
    "            return cell_images, cell_anns, tiss_images, tiss_masks, x_coords, y_coords\n",
    "\n",
    "\n",
    "transforms = trfms.Compose([trfms.ToTensor()])\n",
    "x = MyDataLoader(DATA_PATHS, transforms=transforms, data_to_load='Tissue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(x[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[67], line 92\u001b[0m, in \u001b[0;36mMyDataLoader.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     89\u001b[0m     x_coords\u001b[39m.\u001b[39mappend(x_coord), y_coords\u001b[39m.\u001b[39mappend(y_coord)\n\u001b[0;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 92\u001b[0m     cell_images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms(cell_images)\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_to_load \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTissue\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_to_load \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtissue\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m tiss_images, tiss_masks\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\liemj\\anaconda3\\envs\\REU2023\\Lib\\site-packages\\torchvision\\transforms\\functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'list'>"
     ]
    }
   ],
   "source": [
    "print(x[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
