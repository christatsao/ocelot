{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install keras==2.3.1\n",
    "# !pip install tensorflow==2.1.0\n",
    "# !pip install keras_applications==1.0.8\n",
    "# !pip install image-classifiers==1.0.0\n",
    "# !pip install efficientnet==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#Our project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \n",
    "                                            os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from util.constants import DATA_PATHS\n",
    "from util.dataset import OcelotDatasetLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "# BACKBONE = 'resnet34'\n",
    "# preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "my_device = torch.device(device = 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin_memory = True if my_device == 'cuda' else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # binary segmentation (this parameters are default when you call Unet('resnet34')\n",
    "# model = sm.Unet('resnet34', classes=1, activation='sigmoid')\n",
    "\n",
    "# BACKBONE = 'resnet34'\n",
    "# #preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# learning_rate = 1e-3\n",
    "# weight_decay  = 1e-3\n",
    "# nepochs =10\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# # optimizer_sgd = torch.optim.Adam(model.params(), lr=learning_rate, momentum=0.9,weight_decay=weight_decay)\n",
    "# optimizer_sgd = torch.optim.Adam(model, lr=learning_rate, weight_decay=weight_decay)\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Define the model\n",
    "model = smp.Unet('resnet34', classes=1, activation='sigmoid')\n",
    "\n",
    "# Specify the optimizer, Set Hyperparameters\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "nepochs =10\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#Load our data in our special dataloader\n",
    "TissTrainData = OcelotDatasetLoader(paths = DATA_PATHS, dataToLoad = 'Tissue') #d_transforms\n",
    "\n",
    "\n",
    "#Establish a train/validation split size\n",
    "TrainValSplit = [int(0.8*len(TissTrainData)), len(TissTrainData) - int(0.8*len(TissTrainData))]\n",
    "\n",
    "#Establish our training and validation data using torch's built in random_split on our own formatted data\n",
    "TrainingData, ValidationData = torch.utils.data.random_split(TissTrainData, TrainValSplit)\n",
    "\n",
    "batch_size = 128\n",
    "dataloaderTrain = torch.utils.data.DataLoader(TrainingData, batch_size=batch_size, num_workers=4)\n",
    "dataloaderVal = torch.utils.data.DataLoader(ValidationData, batch_size=batch_size,  num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(TestingData, batch_size=batch_size,  num_workers=4)\n",
    "# # preprocess input\n",
    "# x_train = preprocess_input(x_train)\n",
    "# x_val = preprocess_input(x_val)\n",
    "\n",
    "# model.fit(\n",
    "#    x=x_train,\n",
    "#    y=y_train,\n",
    "#    batch_size=16,\n",
    "#    epochs=100,\n",
    "#    validation_data=(x_val, y_val),\n",
    "# )\n",
    "\n",
    "def compute_accuracy_segmentation(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images = data['image']\n",
    "            targets = data['mask']\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predicted_masks = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            correct_pixels = torch.sum(predicted_masks == targets)\n",
    "            total_correct_pixels += correct_pixels.item()\n",
    "\n",
    "            total_pixels += targets.numel()\n",
    "\n",
    "    accuracy = total_correct_pixels / total_pixels\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def myTrainingLoop(model,dataloaderTrain,dataloaderVal,optimizer,nepoch,my_device,criterion):\n",
    "    ## Training Loop\n",
    "    \n",
    "    model= model.to(dtype= dtype, device = my_device) ## Sending the model to GPU\n",
    "    \n",
    "    ## Setting Up some paramters for analysis\n",
    "    full_loss=[]\n",
    "    training_accuracy_values =[]\n",
    "    validation_accuracy_values =[]\n",
    "    best_val_acc=0\n",
    "    \n",
    "    # Until All Epochs are done\n",
    "    for e in range(nepoch):\n",
    "        print(\"Runing Epoch \",e)\n",
    "        for temp,temp1,temp2,temp3,temp4 in dataloaderTrain: ## Iterator over the data Loader\n",
    "            image = temp2\n",
    "            target = temp3\n",
    "            image = torch.unsqueeze(image,1)\n",
    "            ## Put Model in Training Mode\n",
    "            model.train() \n",
    "            \n",
    "            ## Send inputs to GPU\n",
    "            image = image.to(dtype= dtype, device = my_device) \n",
    "            target = target.to(dtype= torch.long, device = my_device)\n",
    "            \n",
    "            ## Forward pass\n",
    "            output = model(image)\n",
    "            classification_loss = criterion(output, target)\n",
    "            \n",
    "            ## Set Gradients to Zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ## Backward pass\n",
    "            classification_loss.backward()\n",
    "            \n",
    "            ## Optimizer Step\n",
    "            optimizer.step()\n",
    "            \n",
    "            full_loss.append(classification_loss.item())\n",
    "        val_accu = compute_accuracy_segmentation(model,dataloaderVal)\n",
    "        train_accu = compute_accuracy_segmentation(model,dataloaderTrain)\n",
    "        training_accuracy_values.append(train_accu)\n",
    "        validation_accuracy_values.append(val_accu)\n",
    "        print('Validation Accuracy ',val_accu.cpu().numpy())\n",
    "        if(val_accu>best_val_acc):\n",
    "            best_val_acc = val_accu\n",
    "            best_trained_model=copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_trained_model,'./best_trained_model.pt')\n",
    "    return training_accuracy_values, validation_accuracy_values,full_loss\n",
    "\n",
    "#Load into Pytorch's built in DataLoader\n",
    "TissTrainLoader = DataLoader(dataset = TrainingData, batch_size=batch_size, num_workers=4)\n",
    "TissValLoader = DataLoader(ValidationData, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "# define model\n",
    "model = smp.Unet(BACKBONE, encoder_weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_acc,val_acc,full_loss = myTrainingLoop(model,TissTrainLoader,TissValLoader,optimizer,nepochs,my_device,criterion)\n",
    "print(\"Total Runtime\", time.time()-start_time)\n",
    "plt.plot(full_loss,label='Training loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
